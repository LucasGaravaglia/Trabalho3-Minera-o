{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0u0wBaS8R2j0"
      },
      "source": [
        "# **Trabalho 3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GW-SiBuRbfh",
        "outputId": "4d2dc57a-783d-4579-99a1-68a030447a40"
      },
      "outputs": [],
      "source": [
        "!pip install ktrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "t3WyPlkVBdlq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests,json,ktrain,tweepy,io\n",
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from ktrain import text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "log=pd.read_csv('keys.csv')\n",
        "consumerkey=log['key'][0]\n",
        "consumersecret=log['key'][1]\n",
        "accesstoken=log['key'][2]\n",
        "accesstokensecret=log['key'][3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "client = tweepy.Client(accesstoken)\n",
        "\n",
        "#Lendo twetts dos filmes thor amor e trovao, Sonic e Elvis.\n",
        "res1 =  tweepy.Paginator(client.search_recent_tweets, query=\"thorloveandthunder\", tweet_fields=['context_annotations', 'created_at'], max_results=100).flatten(limit=200)\n",
        "res2 =  tweepy.Paginator(client.search_recent_tweets, query=\"Sonic\", tweet_fields=['context_annotations', 'created_at'], max_results=100).flatten(limit=200)\n",
        "res3 =  tweepy.Paginator(client.search_recent_tweets, query=\"elvis\", tweet_fields=['context_annotations', 'created_at'], max_results=100).flatten(limit=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_caracteres(text,carc):\n",
        "    for i in range(len(carc)):\n",
        "            text = text.replace(carc[i],\"\")\n",
        "    return text\n",
        "\n",
        "def remove_stop_words(text,stops):\n",
        "    for i in stops:\n",
        "            idx = text.find(i)\n",
        "            if(idx != -1):\n",
        "                text = text[0:idx]+text[(idx+len(i)):len(text)]\n",
        "    return text\n",
        "\n",
        "def load_tweets(size=1000):\n",
        "    tweets_thor = []\n",
        "    tweets_sonic = []\n",
        "    tweets_elvis = []\n",
        "    for i in range(10):\n",
        "        res1 = tweepy.Paginator(client.search_recent_tweets, query=\"thorloveandthunder\", tweet_fields=['context_annotations', 'created_at'], max_results=100).flatten(limit=200)\n",
        "        res2 = tweepy.Paginator(client.search_recent_tweets, query=\"Sonic\", tweet_fields=['context_annotations', 'created_at'], max_results=100).flatten(limit=200)\n",
        "        res3 = tweepy.Paginator(client.search_recent_tweets, query=\"elvis\", tweet_fields=['context_annotations', 'created_at'], max_results=100).flatten(limit=200)\n",
        "        tweets_thor.append(res1)\n",
        "        tweets_sonic.append(res2)\n",
        "        tweets_elvis.append(res3)\n",
        "    return tweets_thor, tweets_sonic, tweets_elvis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "res1,res2,res3 = load_tweets()\n",
        "\n",
        "\n",
        "#Guardando os twetts em im arquivo json\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "stopwords = set(STOPWORDS)\n",
        "stopwords.update([\"RT\",\"thor\",\"thunder\",\"ThorLoveAndThunder\",\"https\",\"\\n\"])\n",
        "caracteres = \"#@:;|_{}[]()\"\n",
        "info = {\"thor\":{\"text\":[]},\"Sonic\":{\"text\":[]},\"elvis\":{\"text\":[]}}\n",
        "with open('movies.json', 'w') as outfile:\n",
        "    for j in range(10):\n",
        "        for response in res1[j]:\n",
        "            response.text = remove_caracteres(response.text,caracteres)\n",
        "            response.text = remove_stop_words(response.text,stopwords)\n",
        "            info[\"thor\"][\"text\"].append(response.text)\n",
        "        for response2 in res2[j]:\n",
        "            response2.text = remove_caracteres(response2.text,caracteres)\n",
        "            response2.text = remove_stop_words(response2.text,stopwords)\n",
        "            info[\"Sonic\"][\"text\"].append(response2.text)\n",
        "        for response3 in res3[j]:\n",
        "            response3.text = remove_caracteres(response3.text,caracteres)\n",
        "            response3.text = remove_stop_words(response3.text,stopwords)\n",
        "            info[\"elvis\"][\"text\"].append(response3.text)\n",
        "    outfile.write(json.dumps(info))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oOzTtzvVBnYz"
      },
      "outputs": [],
      "source": [
        "s = requests.get('https://raw.githubusercontent.com/ragero/text-collections/master/complete_texts_csvs/review_polarity.csv').content\n",
        "dataset = pd.read_csv(io.StringIO(s.decode('utf-8')),na_values=['?'],skipinitialspace = True)\n",
        "dataset = dataset.sample(frac=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "OFWo51t8-p5E",
        "outputId": "4d909a10-0b6b-489f-d4c3-2e790c6a75b9"
      },
      "outputs": [],
      "source": [
        "(X_train, y_train), (X_test, y_test), preprocess = text.texts_from_df(dataset, \n",
        "                                                                   'text',\n",
        "                                                                   label_columns='class',\n",
        "                                                                   maxlen=64, \n",
        "                                                                   max_features=50000,\n",
        "                                                                   preprocess_mode='bert',\n",
        "                                                                   lang=None,\n",
        "                                                                   val_pct = 0.1,\n",
        "                                                                   )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Omxb016W-3s_",
        "outputId": "3b1cc18c-5059-453d-aae4-a0e33a8ee94d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "maxlen is 64\n",
            "done.\n"
          ]
        }
      ],
      "source": [
        "model = text.text_classifier('bert', (X_train, y_train) , preproc=preprocess)\n",
        "classifier = ktrain.get_learner(model, \n",
        "                             train_data=(X_train, y_train), \n",
        "                             val_data=(X_test, y_test),\n",
        "                             batch_size=64\n",
        "                             )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qvVCDjV_D0l",
        "outputId": "81276c93-1e1c-4372-93b6-6a070be0e181"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.63      0.65       102\n",
            "           1       0.64      0.69      0.67        98\n",
            "\n",
            "    accuracy                           0.66       200\n",
            "   macro avg       0.66      0.66      0.66       200\n",
            "weighted avg       0.66      0.66      0.66       200\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[64, 38],\n",
              "       [30, 68]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier.fit_onecycle(0.00002,8)\n",
        "classifier.validate()\n",
        "predictor = ktrain.get_predictor(classifier.model, preprocess)\n",
        "predictor.predict('this is a good movie')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Trabalho_3_Lucas.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
